{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter,defaultdict,OrderedDict\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.svm import *\n",
    "from imblearn.over_sampling import *\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excle(path):\n",
    "    data_xls = pd.ExcelFile(path)\n",
    "    data = {}\n",
    "    for name in data_xls.sheet_names:\n",
    "        df = pd.read_excel(path,sheet_name=name,header=0,index_col=None)\n",
    "        data[name]=df\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_excle(\"finaldata.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = data[\"internal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case1 = origin[(origin.label==1)]# COVID-19\n",
    "case2 = origin[(origin.label==-1)] # CONTROL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing value\n",
    "all_case = []\n",
    "for k in case1.columns[:-1]:\n",
    "    line1 = case1[k].values\n",
    "    line2 = case2[k].values\n",
    "    line_all = line1.tolist() + line2.tolist()\n",
    "    line_clean = []\n",
    "    info = []\n",
    "    for x in line_all:\n",
    "        if x!=-2: #not missing value\n",
    "            line_clean.append(float(x))\n",
    "    mean_value = np.mean(line_clean)\n",
    "    for x in line_all:\n",
    "        if x !=-2:\n",
    "            info.append(x)\n",
    "        else:\n",
    "            info.append(mean_value)\n",
    "    all_case.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized\n",
    "final_case = []\n",
    "trans_data = np.array(all_case)\n",
    "for i in range(len(trans_data)):\n",
    "    line = trans_data[i]\n",
    "    max_v = max(line)\n",
    "    min_v = min(line)\n",
    "    val = max_v-min_v\n",
    "    final_case.append([(x-min_v)/(val) for x in line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_case1 = np.array(final_case).T.tolist()\n",
    "all_names = [k for k in case1.columns.tolist()[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [] # all 26 indicators\n",
    "set1 = [7, 22, 8, 24, 19, 25, 9, 12, 3, 4, 6, 18, 21]\n",
    "dataset2 = [] #13 statistically significant indictaors\n",
    "dataset3 = [] #13 statistically insignificant indictaors\n",
    "for i in range(len(final_case1)):\n",
    "    if i < 75:\n",
    "        da = final_case1[i] + [1]\n",
    "        dataset.append(da)\n",
    "        text = []\n",
    "        text1 = []\n",
    "        trans = np.array(final_case1[i]).T\n",
    "        for j in range(len(trans)):\n",
    "            if j<=1:\n",
    "                continue\n",
    "            else:\n",
    "                if j in set1:\n",
    "                    text.append(trans[j])\n",
    "                else:\n",
    "                    text1.append(trans[j])\n",
    "        dataset2.append(np.array(text).T.tolist()+[1])\n",
    "        dataset3.append(np.array(text1).T.tolist()+[1])\n",
    "    else:\n",
    "        da = final_case1[i] + [-1]\n",
    "        dataset.append(da)\n",
    "        text = []\n",
    "        text1 = []\n",
    "        trans = np.array(final_case1[i]).T\n",
    "        for j in range(len(trans)):\n",
    "            if j<=1:\n",
    "                continue\n",
    "            else:\n",
    "                if j in set1:\n",
    "                    text.append(trans[j])\n",
    "                else:\n",
    "                    text1.append(trans[j])\n",
    "        dataset2.append(np.array(text).T.tolist()+[-1])\n",
    "        dataset3.append(np.array(text1).T.tolist()+[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing iCov on internal held-out validation data set\n",
    "### 2.1 On the 26 indicators internal cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\"svm\":SVC(C=5,kernel=\"rbf\",max_iter=100000,probability=True),\\\n",
    "         \"LR\":LogisticRegressionCV(n_jobs=30,max_iter=10000),\\# for classifier comparation\n",
    "         \"Adaboost\":AdaBoostClassifier(n_estimators=200),\\ # for classifier comparation\n",
    "         \"RandomForest\":RandomForestClassifier(n_estimators=200,n_jobs=40)# for classifier comparation\n",
    "}\n",
    "def try_different_method(clf,clf_key):\n",
    "    roc = []\n",
    "    tpr = []\n",
    "    recall = []\n",
    "    for i in range(5000):\n",
    "        random.seed(i)\n",
    "        np.random.shuffle(dataset)\n",
    "        split = int(len(dataset)*0.7)\n",
    "        X = np.array([line[:-1] for line in dataset1[:split]])\n",
    "        Y = np.array([line[-1] for line in dataset1[:split]])\n",
    "        X_eval = np.array([line[:-1] for line in dataset1[split:]])\n",
    "        Y_eval = np.array([line[-1] for line in dataset1[split:]])\n",
    "        if clf_key ==\"svm\":\n",
    "            smo = SMOTE(random_state=0)\n",
    "            X,Y = smo.fit_sample(X,Y)\n",
    "        clf.fit(X,Y)\n",
    "        pre = clf.predict(X_eval)\n",
    "        recall.append(recall_score(Y_eval,pre))\n",
    "        roc.append(roc_auc_score(Y_eval,pre))\n",
    "        maxtri = list(confusion_matrix(Y_eval,pre,labels=[1,-1]))\n",
    "        tpr.append(maxtri[1][1]/(maxtri[1][1]+maxtri[1][0]))\n",
    "    recall = np.sort(np.array(recall))\n",
    "    roc = np.sort(np.array(roc))\n",
    "    tpr = np.sort(np.array(tpr))\n",
    "    ca = int(len(roc)*0.05/2)\n",
    "    st = ca if ca!=0 else 0\n",
    "    ed = (-1)*ca if ca!=0 else -1\n",
    "    print(\"Sensitivity: \",round(recall.mean(),3),round(recall.std(),3),round(recall[st],3),round(recall[ed],3))\n",
    "    print(\"AUC: \",round(roc.mean(),3),round(roc.std(),3),round(roc[st],3),round(roc[ed],3))\n",
    "    print(\"Specificity: \",round(tpr.mean(),3),round(tpr.std(),3),round(tpr[st],3),round(tpr[ed],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf_key in clfs.keys():\n",
    "    print(\"the classifier is :\",clf_key)\n",
    "    clf = clfs[clf_key]\n",
    "    try_different_method(clf,clf_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 On the 13 statistical significance indicators internal cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\"svm\":SVC(C=5,kernel=\"rbf\",max_iter=100000,probability=True)}\n",
    "def try_different_method(clf,clf_key):\n",
    "    roc = []\n",
    "    tpr = []\n",
    "    recall = []\n",
    "    for i in range(5000):\n",
    "        random.seed(i)\n",
    "        np.random.shuffle(dataset2)\n",
    "        split = int(len(dataset1)*0.7)\n",
    "        X = np.array([line[:-1] for line in dataset2[:split]])\n",
    "        Y = np.array([line[-1] for line in dataset2[:split]])\n",
    "        X_eval = np.array([line[:-1] for line in dataset2[split:]])\n",
    "        Y_eval = np.array([line[-1] for line in dataset2[split:]])\n",
    "        smo = SMOTE(random_state=0)\n",
    "        X,Y = smo.fit_sample(X,Y)\n",
    "        clf.fit(X,Y)\n",
    "        pre = clf.predict(X_eval)\n",
    "        recall.append(recall_score(Y_eval,pre))\n",
    "        roc.append(roc_auc_score(Y_eval,pre))\n",
    "        maxtri = list(confusion_matrix(Y_eval,pre,labels=[1,-1]))\n",
    "        tpr.append(maxtri[1][1]/(maxtri[1][1]+maxtri[1][0]))\n",
    "    recall = np.sort(np.array(recall))\n",
    "    roc = np.sort(np.array(roc))\n",
    "    tpr = np.sort(np.array(tpr))\n",
    "    ca = int(len(roc)*0.05/2)\n",
    "    st = ca if ca!=0 else 0\n",
    "    ed = (-1)*ca if ca!=0 else -1\n",
    "    print(\"Sensitivity: \",round(recall.mean(),3),round(recall.std(),3),round(recall[st],3),round(recall[ed],3))\n",
    "    print(\"AUC: \",round(roc.mean(),3),round(roc.std(),3),round(roc[st],3),round(roc[ed],3))\n",
    "    print(\"Specificity: \",round(tpr.mean(),3),round(tpr.std(),3),round(tpr[st],3),round(tpr[ed],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf_key in clfs.keys():\n",
    "    print(\"the classifier is :\",clf_key)\n",
    "    clf = clfs[clf_key]\n",
    "    try_different_method(clf,clf_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 On the 13 statistical insignificance indicators internal cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\"svm\":SVC(C=5,kernel=\"rbf\",max_iter=100000,probability=True)}\n",
    "def try_different_method(clf,clf_key):\n",
    "    roc = []\n",
    "    tpr = []\n",
    "    recall = []\n",
    "    for i in range(5000):\n",
    "        random.seed(i)\n",
    "        np.random.shuffle(dataset3)\n",
    "        split = int(len(dataset1)*0.7)\n",
    "        X = np.array([line[:-1] for line in dataset3[:split]])\n",
    "        Y = np.array([line[-1] for line in dataset3[:split]])\n",
    "        X_eval = np.array([line[:-1] for line in dataset3[split:]])\n",
    "        Y_eval = np.array([line[-1] for line in dataset3[split:]])\n",
    "        smo = SMOTE(random_state=0)\n",
    "        X,Y = smo.fit_sample(X,Y)\n",
    "        clf.fit(X,Y)\n",
    "        pre = clf.predict(X_eval)\n",
    "        recall.append(recall_score(Y_eval,pre))\n",
    "        roc.append(roc_auc_score(Y_eval,pre))\n",
    "        maxtri = list(confusion_matrix(Y_eval,pre,labels=[1,-1]))\n",
    "        tpr.append(maxtri[1][1]/(maxtri[1][1]+maxtri[1][0]))\n",
    "    recall = np.sort(np.array(recall))\n",
    "    roc = np.sort(np.array(roc))\n",
    "    tpr = np.sort(np.array(tpr))\n",
    "    ca = int(len(roc)*0.05/2)\n",
    "    st = ca if ca!=0 else 0\n",
    "    ed = (-1)*ca if ca!=0 else -1\n",
    "    print(\"Sensitivity: \",round(recall.mean(),3),round(recall.std(),3),round(recall[st],3),round(recall[ed],3))\n",
    "    print(\"AUC: \",round(roc.mean(),3),round(roc.std(),3),round(roc[st],3),round(roc[ed],3))\n",
    "    print(\"Specificity: \",round(tpr.mean(),3),round(tpr.std(),3),round(tpr[st],3),round(tpr[ed],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf_key in clfs.keys():\n",
    "    print(\"the classifier is :\",clf_key)\n",
    "    clf = clfs[clf_key]\n",
    "    try_different_method(clf,clf_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Indicators selection by isCov\n",
    "### 3.1 Get ranking scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ranges1 = defaultdict(list)\n",
    "max_ranges2 = defaultdict(list)\n",
    "for line in all_names[:-1]:\n",
    "    max_ranges1[line] = []\n",
    "for i in range(0,5000):\n",
    "    random.seed(i)\n",
    "    np.random.shuffle(dataset1)\n",
    "    X = np.array([line[:-1] for line in dataset1])\n",
    "    Y = np.array([line[-1] for line in dataset1])\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    lists1 = []\n",
    "    lists2 = []    \n",
    "    pram = []\n",
    "    KF = KFold(n_splits=5)\n",
    "    for train_index,test_index in KF.split(X):\n",
    "        X_train,X_test = X[train_index],X[test_index]\n",
    "        Y_train,Y_test = Y[train_index],Y[test_index]\n",
    "        smo = SMOTE(random_state=0)\n",
    "        X,Y = smo.fit_sample(X,Y)\n",
    "        clf = LassoCV(max_iter=10000,n_jobs=40)\n",
    "        clf.fit(X,Y)\n",
    "        pre = clf.predict(X_test)\n",
    "        label = [1 if line >0 else -1 for line in pre]\n",
    "        list1 = [abs(line) for line in clf.coef_]\n",
    "        list2 = [line for line in clf.coef_]\n",
    "        lists1.append(list1)\n",
    "        lists2.append(list2)\n",
    "        \n",
    "    lists1 = np.array(lists1).T\n",
    "    lists2 = np.array(lists2).T\n",
    "    mean_list1 = [line.mean() for line in lists1]\n",
    "    mean_list2 = [line.mean() for line in lists2]\n",
    "    name_order1 = dict(zip(all_names[:-1],mean_list1))\n",
    "    name_order1 = dict(sorted(name_order1.items(),key=lambda x:x[1],reverse=True))    \n",
    "    name_order2 = dict(zip(all_names[:-1],mean_list2))\n",
    "    name_order2 = dict(sorted(name_order2.items(),key=lambda x:x[1],reverse=True)) \n",
    "    max_order = list(name_order1.keys())\n",
    "    number = 25\n",
    "    for j in range(len(max_order)):\n",
    "        in_name = max_order[j]\n",
    "        max_ranges1[in_name].append(number)\n",
    "        max_ranges2[in_name].append(name_order2[in_name])\n",
    "        number = number - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ranges = dict()\n",
    "for k in max_ranges1.keys():\n",
    "    max_ranges[k] = sum(max_ranges1[k])\n",
    "max_ranges = dict(sorted(max_ranges.items(),key = lambda x:x[1],reverse = True))\n",
    "max_index = dict()\n",
    "for key in max_ranges.keys():\n",
    "    index = all_names.index(key)\n",
    "    max_index[key]=index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_ranges.keys())\n",
    "info_name = [line for line in max_index.keys()]\n",
    "info = [line for line in max_index.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feeding indicators into iCov according to the isCov model ranking scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多个指标添加\n",
    "nums = []\n",
    "nums_name = []\n",
    "for i in range(len(info)):\n",
    "    if i == 0:\n",
    "        nums.append([info[0]])\n",
    "        nums_name.append([info_name[0]])\n",
    "    else:\n",
    "        nums.append([info[:i+1]])\n",
    "        nums_name.append([info_name[:i+1]]) \n",
    "#单个指标测试\n",
    "nums1 = []\n",
    "nums_name1 = []\n",
    "for i in range(len(info)):\n",
    "    nums1.append([info[i]])\n",
    "    nums_name1.append([info_name[i]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = []\n",
    "roc_std = []\n",
    "roc_ci = [[],[]]\n",
    "recall = []\n",
    "recall_std = []\n",
    "recall_ci = [[],[]]\n",
    "tpr = []\n",
    "tpr_std = []\n",
    "tpr_ci = [[],[]]\n",
    "for j in range(len(nums)):\n",
    "    dataset_tmp = []\n",
    "    print(nums_name[j])\n",
    "    for line in dataset1:\n",
    "        col = []\n",
    "        line_index = nums[j][0] if j !=0 else nums[j]\n",
    "        for n in range(len(line)):\n",
    "            if n in line_index:\n",
    "                col.append(line[n])\n",
    "        dataset_tmp.append(col+[line[-1]])\n",
    "\n",
    "    s2 = []\n",
    "    s5 = []\n",
    "    s6 = []\n",
    "    model = SVC(C=5,kernel=\"rbf\",max_iter=100000)\n",
    "    for i in range(5000):\n",
    "        random.seed(i)\n",
    "        np.random.shuffle(dataset_tmp)\n",
    "        split = int(len(dataset_tmp)*0.7)\n",
    "        X = np.array([line[:-1] for line in dataset_tmp[:split]])\n",
    "        Y = np.array([line[-1] for line in dataset_tmp[:split]])\n",
    "        X_eval = np.array([line[:-1] for line in dataset_tmp[split:]])\n",
    "        Y_eval = np.array([line[-1] for line in dataset_tmp[split:]])\n",
    "        smo = SMOTE(random_state=i)\n",
    "        X,Y = smo.fit_sample(X,Y)\n",
    "        if len(X[0])==1:\n",
    "            X = X.reshape(-1,1)\n",
    "            X_eval = X_eval.reshape(-1,1)\n",
    "        model.fit(X,Y)\n",
    "        pre = model.predict(X_eval)\n",
    "        s2.append(recall_score(Y_eval,pre))\n",
    "        s5.append(roc_auc_score(Y_eval,pre))\n",
    "        maxtri = list(confusion_matrix(Y_eval,pre,labels=[1,-1]))\n",
    "        s6.append(maxtri[1][1]/(maxtri[1][1]+maxtri[1][0]))\n",
    "        \n",
    "\n",
    "    s2 = np.sort(np.array(s2))\n",
    "    s5 = np.sort(np.array(s5))\n",
    "    s6 = np.sort(np.array(s6))\n",
    "    \n",
    "    #0.95 CI\n",
    "    ca = int(len(roc)*0.05/2)\n",
    "    st = ca if ca!=0 else 0\n",
    "    ed = (-1)*ca if ca!=0 else -1\n",
    "    recall_ci[0].append(s2[st])\n",
    "    recall_ci[1].append(s2[ed])        \n",
    "    roc_ci[0].append(s5[st])\n",
    "    roc_ci[1].append(s5[ed])\n",
    "    tpr_ci[0].append(s6[st])\n",
    "    tpr_ci[1].append(s6[ed])\n",
    "    \n",
    "    v2 = [round(s2.mean(),2),round(s2.std(),2)]\n",
    "    v5 = [round(s5.mean(),2),round(s5.std(),2)]\n",
    "    v6 = [round(s6.mean(),2),round(s6.std(),2)]\n",
    "    print(\"Sensitivity:\",s2.mean(),recall_ci[0][j],recall_ci[1][j])\n",
    "    print(\"AUC:\",s5.mean(),roc_ci[0][j],roc_ci[1][j])\n",
    "    print(\"Specificity:\",s6.mean(),tpr_ci[0][j],tpr_ci[1][j])\n",
    "    recall.append(v2[0])\n",
    "    recall_std.append(v2[1])\n",
    "    roc.append(v5[0])\n",
    "    roc_std.append(v5[1])    \n",
    "    tpr.append(v6[0])\n",
    "    tpr_std.append(v6[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc for 13 indicators\n",
    "dataset_tmp = []\n",
    "print(nums_name[12])\n",
    "for line in dataset1:\n",
    "    col = []\n",
    "    for n in range(len(line)):\n",
    "        if n in nums[12][0]:\n",
    "            col.append(line[n])\n",
    "    dataset_tmp.append(col+[line[-1]])\n",
    "model = SVC(C=5,kernel=\"rbf\",max_iter=100000)\n",
    "random.seed(0)\n",
    "np.random.shuffle(dataset_tmp)\n",
    "split = int(len(dataset_tmp)*0.7)\n",
    "X = np.array([line[:-1] for line in dataset_tmp[:split]])\n",
    "Y = np.array([line[-1] for line in dataset_tmp[:split]])\n",
    "X_eval = np.array([line[:-1] for line in dataset_tmp[split:]])\n",
    "Y_eval = np.array([line[-1] for line in dataset_tmp[split:]])\n",
    "smo = SMOTE(random_state=0)\n",
    "X,Y = smo.fit_sample(X,Y)\n",
    "y_score = model.fit(X,Y).decision_function(X_eval)\n",
    "fpr,tprs,threshold = roc_curve(Y_eval, y_score) \n",
    "roc_auc = auc(fpr,tprs)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc for 6 indicators\n",
    "dataset_tmp1 = []\n",
    "print(nums_name[5])\n",
    "for line in dataset1:\n",
    "    col = []\n",
    "    for n in range(len(line)):\n",
    "        if n in nums[5][0]:\n",
    "            col.append(line[n])\n",
    "    dataset_tmp1.append(col+[line[-1]])\n",
    "model = SVC(C=5,kernel=\"rbf\",max_iter=100000)\n",
    "random.seed(0)\n",
    "np.random.shuffle(dataset_tmp1)\n",
    "split = int(len(dataset_tmp1)*0.7)\n",
    "X = np.array([line[:-1] for line in dataset_tmp1[:split]])\n",
    "Y = np.array([line[-1] for line in dataset_tmp1[:split]])\n",
    "X_eval = np.array([line[:-1] for line in dataset_tmp1[split:]])\n",
    "Y_eval = np.array([line[-1] for line in dataset_tmp1[split:]])\n",
    "smo = SMOTE(random_state=0)\n",
    "X,Y = smo.fit_sample(X,Y)\n",
    "y_score = model.fit(X,Y).decision_function(X_eval)\n",
    "fpr1,tpr1,threshold1 = roc_curve(Y_eval, y_score) \n",
    "roc_auc1 = auc(fpr1,tpr1)\n",
    "print(roc_auc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc for 26 indicators\n",
    "dataset_tmp2 = []\n",
    "print(nums_name[25])\n",
    "for line in dataset1:\n",
    "    col = []\n",
    "    for n in range(len(line)):\n",
    "        if n in nums[25][0]:\n",
    "            col.append(line[n])\n",
    "    dataset_tmp2.append(col+[line[-1]])\n",
    "model = SVC(C=5,kernel=\"rbf\",max_iter=100000)\n",
    "random.seed(9)\n",
    "np.random.shuffle(dataset_tmp2)\n",
    "split = int(len(dataset_tmp2)*0.7)\n",
    "X = np.array([line[:-1] for line in dataset_tmp2[:split]])\n",
    "Y = np.array([line[-1] for line in dataset_tmp2[:split]])\n",
    "X_eval = np.array([line[:-1] for line in dataset_tmp2[split:]])\n",
    "Y_eval = np.array([line[-1] for line in dataset_tmp2[split:]])\n",
    "smo = SMOTE(random_state=0)\n",
    "X,Y = smo.fit_sample(X,Y)\n",
    "y_score = model.fit(X,Y).decision_function(X_eval)\n",
    "fpr2,tpr2,threshold2 = roc_curve(Y_eval, y_score) \n",
    "roc_auc2 = auc(fpr2,tpr2)\n",
    "print(roc_auc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing iCov and isCov model on external cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin1 = data[\"external\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case1 = origin1[origin1.label==1]\n",
    "test_case2 = origin1[origin1.label==-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_case = []\n",
    "for k in case1.columns[:-1]:\n",
    "    line1 = case1[k].values\n",
    "    line2 = case2[k].values\n",
    "    line3 = test_case1[k].values\n",
    "    line4 = test_case2[k].values\n",
    "    line_all = line1.tolist() + line2.tolist()\n",
    "    line_all1 = line1.tolist() + line2.tolist()+line3.tolist() + line4.tolist()\n",
    "    line_clean = []\n",
    "    info = []\n",
    "    for x in line_all:\n",
    "        if x!=-2: \n",
    "            line_clean.append(float(x))\n",
    "    mean_value = np.mean(line_clean)\n",
    "    for x in line_all1:\n",
    "        if x !=-2:\n",
    "            info.append(x)\n",
    "        else:\n",
    "            info.append(mean_value)\n",
    "    all_case.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_case = []\n",
    "trans_data = np.array(all_case)\n",
    "for i in range(len(trans_data)):\n",
    "    line = trans_data[i]\n",
    "    max_v = max(line)\n",
    "    min_v = min(line)\n",
    "    val = max_v-min_v\n",
    "    final_case.append([(x-min_v)/(val) for x in line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_case1 = np.array(final_case).T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "set1 = [9, 24, 10, 26, 21, 27, 11, 14, 5, 6, 8, 20, 23]\n",
    "dataset2 = []\n",
    "dataset3 = []\n",
    "for i in range(len(final_case1)):\n",
    "    if (i < 75) or (i>=732 and i<751):\n",
    "        da = final_case1[i] + [1]\n",
    "        dataset.append(da)\n",
    "        text = []\n",
    "        text1 = []\n",
    "        trans = np.array(final_case1[i]).T\n",
    "        for j in range(len(trans)):\n",
    "            if j<=1:\n",
    "                continue\n",
    "            else:\n",
    "                if j in set1:\n",
    "                    text.append(trans[j])\n",
    "                else:\n",
    "                    text1.append(trans[j])\n",
    "        dataset2.append(np.array(text).T.tolist()+[1])\n",
    "        dataset3.append(np.array(text1).T.tolist()+[1])\n",
    "    else:\n",
    "        da = final_case1[i] + [-1]\n",
    "        dataset.append(da)\n",
    "        text = []\n",
    "        text1 = []\n",
    "        trans = np.array(final_case1[i]).T\n",
    "        for j in range(len(trans)):\n",
    "            if j<=1:\n",
    "                continue\n",
    "            else:\n",
    "                if j in set1:\n",
    "                    text.append(trans[j])\n",
    "                else:\n",
    "                    text1.append(trans[j])\n",
    "        dataset2.append(np.array(text).T.tolist()+[-1])\n",
    "        dataset3.append(np.array(text1).T.tolist()+[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainset = dataset[:732]\n",
    "Testset = dataset[732:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums1 = [7, 22, 8, 24, 19, 25, 9, 12, 3, 4, 6, 18, 21] # 13 statistically significant indictaors\n",
    "nums2 = [15, 22, 7, 6, 8, 12] # Top 6 isCov selected indictaors\n",
    "nums3 = [15, 22, 7, 6, 8, 12, 17, 2, 11, 16, 20, 21, 24] # Top 13 isCov selected indictaors\n",
    "nums4 = [i for i in range(26)] # all 26 indictaors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_select = []\n",
    "dataset_select1 = []\n",
    "# build training set\n",
    "for line in Trainset:\n",
    "    col = []\n",
    "    for n in range(len(line)):\n",
    "        if n in nums1:# varible nums1 can be replaced for testing different indicators data set. For example, nums2.\n",
    "            col.append(line[n])\n",
    "    dataset_select.append(col+[line[-1]])\n",
    "# build testing set    \n",
    "for line in Testset:\n",
    "    col = []\n",
    "    for n in range(len(line)):\n",
    "        if n in nums1: # varible nums1 can be replaced for testing different indicators data set. For example, nums2.\n",
    "            col.append(line[n])\n",
    "    dataset_select1.append(col+[line[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=5,kernel=\"rbf\",max_iter=100000)\n",
    "# clf = LogisticRegressionCV(n_jobs=30,max_iter=10000) # for testing other classifer\n",
    "# clf = AdaBoostClassifier(n_estimators=200) # for testing other classifer\n",
    "# clf = RandomForestClassifier(n_estimators=200,n_jobs=40) # for testing other classifer\n",
    "roc = []\n",
    "recall = []\n",
    "tpr = []\n",
    "np.random.shuffle(dataset_select)\n",
    "np.random.shuffle(dataset_select1)\n",
    "X = np.array([line[:-1] for line in dataset_select])\n",
    "Y = np.array([line[-1] for line in dataset_select])\n",
    "X_eval = np.array([line[:-1] for line in dataset_select1])\n",
    "Y_eval = np.array([line[-1] for line in dataset_select1])\n",
    "smo = SMOTE(random_state=i)\n",
    "X,Y = smo.fit_sample(X,Y)\n",
    "clf.fit(X,Y)\n",
    "pre = clf.predict(X_eval)\n",
    "recall.append(recall_score(Y_eval,pre))\n",
    "roc.append(roc_auc_score(Y_eval,pre))\n",
    "maxtri = list(confusion_matrix(Y_eval,pre,labels=[1,-1]))\n",
    "tpr.append(maxtri[1][1]/(maxtri[1][1]+maxtri[1][0]))\n",
    "tpr = np.sort(np.array(tpr))\n",
    "recall = np.sort(np.array(recall))\n",
    "roc = np.sort(np.array(roc))\n",
    "\n",
    "print(\"auc: \",round(roc.mean(),3))\n",
    "print(\"sensitivity: \",round(recall,3))\n",
    "print(\"specificity: \",round(tpr,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
